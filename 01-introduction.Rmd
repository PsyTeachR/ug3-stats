# Introduction

## Goal of this course

The goal of this course is to teach you how to simulate and analyze the various types of datasets you are likely to encounter as a psychologist. The focus is on behavioral data---e.g., measures of reaction time, perceptual judgments, choices, decision, ratings on a survey, hours of sleep, etc.---usually collected in the context of a study or experiment. 

This course emphasizing approaches that maximize **flexibility**, **generalizability**, and **reproducibility**. You may have heard talk in the media about psychology being in the throes of various 'crises'. There have been some high-profile replication failures that have contributed to the impression that all is not well. There have also been a number of demonstrations that the standard approaches to data analysis in psychology are flawed, in that they allow researchers to present results as clean-cut and confirmatory while hiding various analyses that have been pursued and discarded while seeking to attain the desired result. But it is not just the field of psychology where such problems can be found---the problem is widespread, encompassing other fields of study as well. And the truth is that a certain level of self-criticism and self-reflection can also be seen positively---as a sign of a healthy discipline. Whatever your take, there is room for improvement, and the purpose of this course is to give you tools to ensure that your own analyses are not only statistically sound, but also as generalizable and reproducible as possible. 

### Flexibility

The approach taken in this course differs from other courses in that it emphasizes learning a flexible regression modeling framework rather than teaching 'recipes' for dealing with different types of data, and assumes that the fundamental type of data you will need to analyze will be `r glossary("multilevel")` and also that you will need to deal not only with continuous measurements but also ordinal measurements (ratings on a Likert scale), counts (number of times particular event types have taken place), and nominal data (what category something falls into).

The most flexible approach available is the General Linear Model approach, in which some `r glossary("response variable")` is modeled in terms of a weighted linear sum of `r glossary("predictor variable", "predictor variables")`. A simple mathematical example of one such formula is

$$Y_i = \beta_0 + \beta_1 X_i + e_i$$

where $Y_i$ is the measured response for observation $i$, modeled in terms of an `r glossary("intercept")` term plus the effect of `r glossary("predictor variable", "predictor")` $X_i$ weighted by coefficient $\beta_1$ and `r glossary("residual error")` term $e_i$, which reflects unmodeled variance.

You might recognize the above equation as representing the equation for a line ($y = mx + b$), with $\beta_0$ playing the role of the `r glossary("intercept", "y-intercept")` and $\beta_1$ playing the role of the `r glossary("slope")`. The $e_i$ term reflects what is left of observation $i$ after accounting for the the intercept and the predictor $X_i$.

A terminological convention in this course is that Greek letters ($\beta$, $\rho$, $\tau$) represent unobserved `r glossary("population parameter", "population parameters")` while Latin letters ($X$, $Y$) represent observed values.

This linear formulation is highly general, and we will see how it can be used to model different kinds of relationships between different kinds of variables. One limitation of the current course is that it focuses mainly on `r glossary("univariate")` data, where a single `r glossary("response variable")` is the focus of analysis. It is often the case that you will be dealing with multiple response variables on the same subjects, but modeling them all simultaneously is technically very difficult and beyond the scope of this course. A simpler approach (and the one adopted here) is to analyze each response variable in a separate univariate analysis.

## Generalizability

The term `r glossary("generalizability")` refers to the degree to which findings from a study can be readily applied to situations beyond the particular context (subjects, stimuli, task, etc.) in which the data were collected. At best, our findings would apply to all members of the human species across a wide variety of contexts; at worst, they would apply only to those specific people observed in the specific context of our study. Most studies fall somewhere between these two opposing poles.

The generalizability of a finding depends on several factors: how the study was designed, what materials were used, how subjects were recruited, the nature of the task given to the subjects, **and the way the data were analyzed**. It is this last point that we will focus on in this course. When analyzing a dataset, if you want to make generalizable claims, you must make decisions about what would count as a replication of your study---about which aspects would remain fixed across replications, and which aspects you would allow to vary. Unfortunately, you will sometimes find that data have been analyzed in a way that does not support generalization in the broadest sense, often because analyses underestimate the influence of ideosyncratic features of stimulus materials or experimental task on the observed result [@yarkoni_2019].

## Reproduciblity and Transparency

The term `r glossary("reproducibility")` refers to the degree to which it is possible to reproduce the pattern of findings in a study under various circumstances.

We say a finding is *analytically* or *computationally* reproducible if, given the raw data, we can obtain the same pattern of results. Note that this is different from saying a finding is **replicable**, which refers to being able to reproduce the finding in **new samples.** There is not widespread agreement about these terms, but it is convenient to view analytic reproducibility and replicability as two different but related types of reproducibility, with the former capturing reproducibility across analysts (or among the same analysts over time) and the latter reflecting reproducibility across participants. 

Ensuring that analyses are reproducible is a hard problem. If you fail to properly document your own analyses, or the software that you used gets modified or goes out of date and becomes unavailable, you may have trouble reproducing your own findings!

Another important property of analyses is `r glossary("transparency")`: the extent to which all the steps in some research study have been made available. A study may be transparent but not reproducible, and vice versa. It is important to use a workflow that promotes transparency. This makes the 'edit-and-execute' workflow of script programming ideal for data analysis, far superior to the 'point-and-click' workflow of most commercial statistical programs. By writing code, you make the logic and decision process explicit to others and easy to reconstruct.

## A simulation-based approach

A final characteristic that distinguishes this course is that it uses a simulation-based approach to learning about statistical models.

## What you will learn

- TODO
