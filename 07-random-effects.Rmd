# Specifying random effects in linear mixed-effects models

```{r setup, include=FALSE}
library("kableExtra")
library("tidyverse")

## paste
.p <- paste0

## .fraction
.f <- function(x, y) {
  paste0("\\frac{", x, "}{", y, "}")
}

## y-bar
.yb1 <- function(x) {
  paste0("$\\bar{Y}_{", x, "}$")
}

.yb2 <- function(x) {
  paste0("\\bar{Y}_{", x, "}")
}

## subtraction term
.st <- function(x, y, bracket = NULL) {
  if (is.null(bracket)) {
    paste0(x, " - ", y)
  } else {
    paste0(bracket[1], x, " - ", y, bracket[2])
  }
}

.rb <- c("(", ")")
.dr <- c("\\displaystyle\\left(", "\\right)")
.ds <- c("\\displaystyle\\left[", "\\right]")
```

## Learning objectives

* specify maximal random effects structure for complex designs
* simulate data for a design with crossed random factors of subjects and stimuli
* estimate parameters for linear mixed-effects models with crossed random factors

## Web app

- [Demo of crossed random effects](http://shiny.psy.gla.ac.uk/Dale/crossed)

## Specifying random effects

We'll start out with some interactive tasks where you are given data to examine and asked to specify the maximal random effects structure. The data are stored in [this zip file](data/rfx_data.zip). The archive includes four R binary files (`.rds`), which you can load in using the `readRDS()` function. Extract it and set your working directory to where the resulting subdirectory `rfx_data/` is located. 

Use the code below to load them in.

```{r load-in0, echo=FALSE}
ds1 <- readRDS("data/dataset1.rds")
ds2 <- readRDS("data/dataset2.rds")
ds3 <- readRDS("data/dataset3.rds")
ds4 <- readRDS("data/dataset4.rds")
```

```{r load-in, eval=FALSE}
ds1 <- readRDS("rfx_data/dataset1.rds")
ds2 <- readRDS("rfx_data/dataset2.rds")
ds3 <- readRDS("rfx_data/dataset3.rds")
ds4 <- readRDS("rfx_data/dataset4.rds")
```

Each object has data from a hypothetical study with a factorial design. Your task is to specify the design formula for the mixed-effects model you would fit to the data. To determine the appropriate design, you will need to inspect each dataset carefully. You want to treat subjects and stimuli as random factors. If the dataset does not include one of the random factors you can omit it from the formula.

Each dataset may have some or all of the following variables:

| Variable  | Description                                 |
|-----------+---------------------------------------------|
| `subj_id` | subject identifier                          |
| `item_id` | stimulus identifier                         |
| `A`       | a categorical factor (independent variable) |
| `B`       | a categorical factor (independent variable) |
| `C`       | a categorical factor (independent variable) |
| `DV`      | the dependent variable                      |

Your task is to determine the appropriate mixed-effects model specification including the maximal random-effects structure, and write the `formula` part of the `lme4::lmer()` model as your answer.  For all of the models, the variable `DV` should appear on the left-hand side of the formula; i.e., it should be of the form `DV ~ A + ...`.  If a given dataset includes both `subj_id` and `item_id`, you need to specify random effects for both of them; if not, only specify the random effects for the one that appear in the data.  Likewise, any IV that does not appear in the dataset should not be included anywhere in the formula.

For instance, had one of these datasets been the `lme4::sleepstudy` data, you would have replaced `ss_form <- NULL` with:

```{r ss-form, eval=FALSE}
ss_form <- Reaction ~ Days + (Days | Subject)
```

In other words: __all you need is the formula, NOT the call to `lme4::lmer()`; you are not actually fitting any model to the data.__

#### Dataset 1

Investigate the experimental design for `dataset1` and type the appropriate model formula.

`r hide()`

`DV ~ A * B * C + (A * B | subj_id)`

```{r ds1-sol}
ds1 %>% count(subj_id, A, B, C) %>% filter(subj_id == 1L)
```

`r unhide()`

#### Dataset 2

Investigate the experimental design for `dataset2` and type the appropriate model formula.

`r hide()`

```
DV ~ A * B * C + (A + B + C + A:B + A:C + B:C | subj_id) +
                 (A * B * C | item_id)
```

```{r ds2-sol}
ds2 %>% count(subj_id, A, B, C) %>% filter(subj_id == 1L)
```

#### Dataset 3

Investigate the experimental design for `dataset3` and type the appropriate model formula.

`r hide()`

`DV ~ A * B + (A | subj_id) + (B | item_id)`

```{r ds3-sol1}
ds3 %>% count(subj_id, A, B) %>% filter(subj_id == 1L)
```

```{r ds3-sol2}
ds3 %>% count(item_id, A, B) %>% filter(item_id == 1L)
```

`r unhide()`

#### Dataset 4

Investigate the experimental design for `dataset4` and type the appropriate model formula.

`r hide()`

`DV ~ A * B + (1 | subj_id) + (A * B | item_id)`

```{r ds4-sol1}
ds4 %>% count(subj_id, A, B) %>% filter(subj_id == 1L)
```

```{r ds4-sol2}
ds4 %>% count(item_id, A, B) %>% filter(item_id == 1L)
```

`r unhide()`

## Simulating data with crossed random factors

For this first set of exercises, we will generate simulated data corresponding to an experiment with a single, two-level factor (independent variable) that is within-subjects and between-items.  Let's imagine that the experiment involves lexical decisions to a set of words (e.g., is "PINT" a word or nonword?), and the dependent variable is response time (in milliseconds), and the independent variable is word type (noun vs verb).  We want to treat both subjects and words as random factors (so that we can generalize to the population of events where subjects encounter words).  You can play around with the web app below (or [click here to open it in a new window](http://shiny.psy.gla.ac.uk/Dale/crossed){target="_blank"}), which allows you to manipulate the data-generating parameters and see their effect on the data.

```{r webapp, echo=FALSE, fig.cap="*Web app for crossed random effects.*"}
knitr::include_app("http://shiny.psy.gla.ac.uk/Dale/crossed", height = "600px")
```

Here is the DGP for response time $Y_{si}$ for subject $s$ and item $i$:

*Level 1:*

\begin{equation}
Y_{si} = \beta_{0s} + \beta_{1} X_{i} + e_{si}
\end{equation}

*Level 2:*

\begin{equation}
\beta_{0s} = \gamma_{00} + S_{0s} + I_{0i}
\end{equation}

\begin{equation}
\beta_{1} = \gamma_{10} + S_{1s}
\end{equation}

*Variance Components:*

\begin{equation}
\langle S_{0s}, S_{1s} \rangle \sim N\left(0, \mathbf{\Sigma}\right) 
\end{equation}

\begin{equation}
\mathbf{\Sigma} = \left(\begin{array}{cc}{\tau_{00}}^2 & \rho\tau_{00}\tau_{11} \\
         \rho\tau_{00}\tau_{11} & {\tau_{11}}^2 \\
         \end{array}\right) 
\end{equation}

\begin{equation}
I_{0s} \sim N\left(0, {\omega_{00}}^2\right) 
\end{equation}

\begin{equation}
e_{si} \sim N\left(0, \sigma^2\right)
\end{equation}

In the above equation, $X_i$ is a numerical predictor coding which condition the item $i$ is in; e.g., -.5 for noun, .5 for verb.

We could just reduce levels 1 and 2 to 

$$Y_{si} = \beta_0 + S_{0s} + I_{0i} + (\beta_1 + S_{1s})X_{i} + e_{si}$$

where:

|Parameter    | Symbol| Description                                       |
|:------------|:------|:--------------------------------------------------|
| \(Y_{si}\)  | `Y`   | RT for subject \(s\) responding to item \(i\);    |
| \(\beta_0\) | `b0`  | grand mean;                                       |
| \(S_{0s}\)  | `S_0s` | random intercept for subject \(s\);               |
| \(I_{0i}\)  | `I_0i` | random intercept for item \(i\);                  |
| \(\beta_1\) | `b1` | fixed effect of word type (slope);                |
| \(S_{1s}\)  | `S_1s` | by-subject random slope;                          |
| \(X_{i}\)   | `cond` | deviation-coded predictor variable for word type; |
| \(\tau_{00}\) | `tau_00` | by-subject random intercept standard deviation |
| \(\tau_{11}\) | `tau_11` | by-subject random slope standard deviation |
| \(\rho\)    | `rho` | correlation between random intercept and slope |
| \(\omega_{00}\) | `omega_00` | by-item random intercept standard deviation |
| \(e_{si}\)  | `err` | residual error                                   |
| \(\sigma\)  | `sig` | residual error standard deviation                 |

### Set up the environment and define the parameters for the DGP

If you want to get the same results as everyone else for this exercise, then we all should seed the random number generator with the same value.  While we're at it, let's load in the packages we need.

```{r sim-setup, message=FALSE}
library("lme4")
library("tidyverse")

set.seed(11709)  
```

Now let's define the parameters for the DGP (data generating process).

```{r dgp-params}
nsubj <- 100 # number of subjects
nitem <- 50  # must be an even number

b0 <- 800 # grand mean
b1 <- 80 # 80 ms difference
effc <- c(-.5, .5) # deviation codes

omega_00 <- 80 # by-item random intercept sd (omega_00)

## for the by-subjects variance-covariance matrix
tau_00 <- 100 # by-subject random intercept sd
tau_11 <- 40 # by-subject random slope sd
rho <- .2 # correlation between intercept and slope

sig <- 200 # residual (standard deviation)
```

You'll create three tables:

| Name       | Description                                                          |
|:-----------|:---------------------------------------------------------------------|
| `subjects` | table of subject data including `subj_id` and subject random effects |
| `items`    | table of stimulus data including `item_id` and item random effect    |
| `trials`   | table of trials enumerating encounters between subjects/stimuli      |

Then you will merge together the information in the three tables, and calculate the response variable according to the model formula above.

** Generate a sample of stimuli

Let's randomly generate our `r nitem` items. Create a tibble called `item` like the one below, where `iri` are the by-item random intercepts (drawn from a normal distribution with variance \(\omega_{00}^2\) ` `iri_sd^2`).  Half of the words are of type NOUN (`cond` ` -.5) and half of type VERB (`cond` ` .5).

```{r item-tib}
items <- tibble(item_id = 1:nitem,
                cond = rep(c(-.5, .5), times = nitem / 2),
                I_0i = rnorm(nitem, 0, sd = omega_00))
```

```{r items}
items
```

`r hide("Hint for making cond")`

`rep()`

`r unhide()`

`r hide("Hint for making item random effects")`

`rnorm()`

`r unhide()`

`r hide("Solution")`

```{r item-tib-sol, eval=FALSE}
items <- tibble(item_id = 1:nitem,
                cond = rep(c(-.5, .5), times = nitem / 2),
                I_0i = rnorm(nitem, 0, sd = omega_00))

items
```

```{r items-print, echo=FALSE}
items
```

`r unhide()`

### Generate a sample of subjects

To generate the by-subject random effects, you will need to generate data from a *bivariate normal distribution*.  To do this, we will use the function `MASS::mvrnorm`.  

<div class="warning">

REMEMBER: do not run `library("MASS")` just to get this one function, because `MASS` has a function `select()` that will overwrite the tidyverse version. Since all we want from MASS is the `mvrnorm()` function, we can just access it directly by the `pkgname::function` syntax, i.e., `MASS::mvrnorm()`.

</div>

Your subjects table should look like this:

`r hide("Click to reveal full table")`

```{r subj-tbl1, echo = FALSE}
cov <- rho * tau_00 * tau_11

mx <- matrix(c(tau_00^2, cov,
               cov,      tau_11^2),
             nrow = 2)

by_subj_rfx <- MASS::mvrnorm(nsubj, mu = c(S_0s = 0, S_1s = 0), Sigma = mx)

subjects <- as_tibble(by_subj_rfx) %>%
  mutate(subj_id = row_number()) %>%
  select(subj_id, everything())

subjects %>% print(n = +Inf)
```

`r unhide()`

`r hide("Hint 1")`

recall that:

* *`tau_00`*: by-subject random intercept standard deviation
* *`tau_11`*: by-subject random slope standard deviation
* *`rho`* : correlation between intercept and slope

`r unhide()`

`r hide("Hint 2")`

`covariance = rho * tau_00 * tau_11`

`r unhide()`

`r hide("Hint 3")`

```{r hint3, eval=FALSE}
matrix(    tau_00^2,            rho * tau_00 * tau_11,
        rho * tau_00 * tau_11,      tau_11^2, ...)

```

`r unhide()`

`r hide("Hint 4")`

```{r hint4, eval=FALSE}
as_tibble(mx) %>%
  mutate(subj_id = ...)
```

`r unhide()`

`r hide("Solution")`

```{r code-subj-sol, eval=FALSE}
cov <- rho * tau_00 * tau_11

mx <- matrix(c(tau_00^2, cov,
               cov,      tau_11^2),
             nrow = 2)

by_subj_rfx <- MASS::mvrnorm(nsubj, mu = c(S_0s = 0, S_1s = 0), Sigma = mx)

subjects <- as_tibble(by_subj_rfx) %>%
  mutate(subj_id = row_number()) %>%
  select(subj_id, everything())

subjects %>% print(n = +Inf)
```

```{r print-subj, echo = FALSE}
subjects %>% print(n = +Inf)
```

`r unhide()`

### Generate a sample of encounters (trials)

Each trial is an *encounter* between a particular subject and stimulus.  In this experiment, each subject will see each stimulus.  Generate a table `trials` that lists the encounters in the experiments. Note: each participant encounters each stimulus item once.  Use the `crossing()` function to create all possible encounters.

Now apply this example to generate the table below, where `err` is the residual term, drawn from \(N \sim \left(0, \sigma^2\right)\), where \(\sigma\) is `err_sd`.

```{r gen-encounters, echo=FALSE}
trials <- crossing(subj_id = subjects %>% pull(subj_id),
                   item_id = items %>% pull(item_id)) %>%
  mutate(err = rnorm(nrow(.), mean = 0, sd = sig))

trials
```


`r hide()`

```{r trials2, eval=FALSE}
trials <- crossing(subj_id = subjects %>% pull(subj_id),
                   item_id = items %>% pull(item_id)) %>%
  mutate(err = rnorm(nrow(subjects) * nrow(items), mean = 0, sd = sig))
```

```{r trials2-print, echo=FALSE}
trials
```

`r unhide()`

### Join `subjects`, `items`, and `trials`

Merge the information in `subjects`, `items`, and `trials` to create the full dataset `dat_sim`, which looks like this:

```{r make-dat, echo=FALSE}
dat_sim <- subjects %>%
  inner_join(trials, "subj_id") %>%
  inner_join(items, "item_id") %>%
  arrange(subj_id, item_id) %>%
  select(subj_id, item_id, S_0s, I_0i, S_1s, cond, err)

dat_sim
```

`r hide()`

```{r dat-sim-sol, eval=FALSE}
dat_sim <- subjects %>%
  inner_join(trials, "subj_id") %>%
  inner_join(items, "item_id") %>%
  arrange(subj_id, item_id) %>%
  select(subj_id, item_id, S_0s, I_0i, S_1s, cond, err)

dat_sim
```

```{r sim-print, echo=FALSE}
dat_sim
```

`r unhide()`

### Create the response variable

Add the response variable `Y` to dat according to the model formula:

$$Y_{si} = \beta_0 + S_{0s} + I_{0i} + (\beta_1 + S_{1s})X_{i} + e_{si}$$

so that the resulting table (`dat_sim2`) looks like this:

```{r dat-sim2, echo=FALSE}
dat_sim2 <- dat_sim %>%
  mutate(Y = b0 + S_0s + I_0i + (S_1s + b1) * cond + err) %>%
  select(subj_id, item_id, Y, everything())

dat_sim2
```

Note: this is the full **decomposition table** for this model.

`r hide()`

```{r dat-sim2-sol, eval=FALSE}
dat_sim2 <- dat_sim %>%
  mutate(Y = b0 + S_0s + I_0i + (S_1s + b1) * cond + err) %>%
  select(subj_id, item_id, Y, everything())

dat_sim2
```

```{r dat-sim2-print, echo=FALSE}
dat_sim2
```

`r unhide()`

## Fitting the model

Now that you have created simulated data, estimate the model using `lme4::lmer()`, and run `summary()`.

`r hide()`

```{r fit-model}
mod_sim <- lmer(Y ~ cond + (1 + cond | subj_id) + (1 | item_id),
                dat_sim2, REML = FALSE)

summary(mod_sim, corr = FALSE)
```

`r unhide()`

Now see if you can identify the data generating parameters in the output of `summary()`.

```{r dgp1, include=FALSE}
srfx <- attr(VarCorr(mod_sim)$subj_id, "stddev")
irfx <- attr(VarCorr(mod_sim)$item_id, "stddev")
rc <- attr(VarCorr(mod_sim)$subj_id, "correlation")[1, 2]

res <- attr(VarCorr(mod_sim), "sc")

ffx <- fixef(mod_sim)
```

First, try to find \(\beta_0\) and \(\beta_1\).

`r hide("Solution: Fixed effects")`

```{r fef-sol, echo = FALSE}
tribble(~parameter, ~variable, ~input, ~estimate,
        "\\(\\hat{\\beta}_0\\)", "`b0`", b0, as.numeric(round(ffx[1], 3)),
        "\\(\\hat{\\beta}_1\\)", "`b1`", b1, as.numeric(round(ffx[2], 3))) %>%
  knitr::kable()
```

`r unhide()`

Now try to find estimates of random effects parameters \(\tau_{00}\), \(\tau_{11}\), \(\rho\), \(\omega_{00}\), and \(\sigma\).

`r hide("Solution: Random effects parameters")`

```{r rfx-sol, echo = FALSE}
tribble(~parameter, ~variable, ~input, ~estimate,
        "\\(\\hat{\\tau}_{00}\\)", "`tau_00`", tau_00,
        as.numeric(round(srfx[1], 3)),
        "\\(\\hat{\\tau}_{11}\\)", "`tau_11`", tau_11,
        as.numeric(round(srfx[2], 3)),
        "\\(\\hat{\\rho}\\)", "`rho`", rho, as.numeric(round(rc, 3)),
        "\\(\\hat{\\omega}_{00}\\)", "`omega_00`", omega_00,
        as.numeric(round(irfx[1], 3)),
        "\\(\\hat{\\sigma}\\)", "`sig`", sig,
        as.numeric(round(res, 3))) %>%
  knitr::kable()
```

`r unhide()`
